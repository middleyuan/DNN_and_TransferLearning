{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3-1 softmax only -- training time 6.95s, accuracy 82.70% ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5\n",
    "\n",
    "\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## restore HW2 model ##\n",
    "restore_saver = tf.train.import_meta_graph(\"Team58_HW2\\Team58_HW2.ckpt.meta\")\n",
    "\n",
    "## get tensor from HW2 ##\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting trainable variable ##\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(0.01, name=\"Adamgram\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "HW3_1_saver = tf.train.Saver() # create saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Team58_HW2\\Team58_HW2.ckpt\n",
      "0\tValidation loss: 1.5964\tBest loss: 1.5964\tAccuracy: 26.67%\n",
      "1\tValidation loss: 1.5050\tBest loss: 1.5050\tAccuracy: 40.00%\n",
      "2\tValidation loss: 1.4554\tBest loss: 1.4554\tAccuracy: 44.00%\n",
      "3\tValidation loss: 1.4194\tBest loss: 1.4194\tAccuracy: 49.33%\n",
      "4\tValidation loss: 1.3876\tBest loss: 1.3876\tAccuracy: 50.67%\n",
      "5\tValidation loss: 1.3605\tBest loss: 1.3605\tAccuracy: 54.67%\n",
      "6\tValidation loss: 1.3437\tBest loss: 1.3437\tAccuracy: 56.00%\n",
      "7\tValidation loss: 1.3365\tBest loss: 1.3365\tAccuracy: 56.67%\n",
      "8\tValidation loss: 1.3361\tBest loss: 1.3361\tAccuracy: 57.33%\n",
      "9\tValidation loss: 1.3348\tBest loss: 1.3348\tAccuracy: 58.00%\n",
      "10\tValidation loss: 1.3298\tBest loss: 1.3298\tAccuracy: 57.33%\n",
      "11\tValidation loss: 1.3221\tBest loss: 1.3221\tAccuracy: 59.33%\n",
      "12\tValidation loss: 1.3148\tBest loss: 1.3148\tAccuracy: 59.33%\n",
      "13\tValidation loss: 1.3091\tBest loss: 1.3091\tAccuracy: 58.67%\n",
      "14\tValidation loss: 1.3037\tBest loss: 1.3037\tAccuracy: 58.00%\n",
      "15\tValidation loss: 1.2978\tBest loss: 1.2978\tAccuracy: 58.00%\n",
      "16\tValidation loss: 1.2915\tBest loss: 1.2915\tAccuracy: 58.00%\n",
      "17\tValidation loss: 1.2854\tBest loss: 1.2854\tAccuracy: 60.00%\n",
      "18\tValidation loss: 1.2803\tBest loss: 1.2803\tAccuracy: 60.67%\n",
      "19\tValidation loss: 1.2773\tBest loss: 1.2773\tAccuracy: 59.33%\n",
      "20\tValidation loss: 1.2766\tBest loss: 1.2766\tAccuracy: 61.33%\n",
      "21\tValidation loss: 1.2769\tBest loss: 1.2766\tAccuracy: 61.33%\n",
      "22\tValidation loss: 1.2771\tBest loss: 1.2766\tAccuracy: 60.67%\n",
      "23\tValidation loss: 1.2749\tBest loss: 1.2749\tAccuracy: 60.00%\n",
      "24\tValidation loss: 1.2701\tBest loss: 1.2701\tAccuracy: 62.00%\n",
      "25\tValidation loss: 1.2643\tBest loss: 1.2643\tAccuracy: 62.00%\n",
      "26\tValidation loss: 1.2585\tBest loss: 1.2585\tAccuracy: 61.33%\n",
      "27\tValidation loss: 1.2534\tBest loss: 1.2534\tAccuracy: 63.33%\n",
      "28\tValidation loss: 1.2489\tBest loss: 1.2489\tAccuracy: 64.67%\n",
      "29\tValidation loss: 1.2443\tBest loss: 1.2443\tAccuracy: 65.33%\n",
      "30\tValidation loss: 1.2391\tBest loss: 1.2391\tAccuracy: 65.33%\n",
      "31\tValidation loss: 1.2340\tBest loss: 1.2340\tAccuracy: 64.67%\n",
      "32\tValidation loss: 1.2288\tBest loss: 1.2288\tAccuracy: 65.33%\n",
      "33\tValidation loss: 1.2221\tBest loss: 1.2221\tAccuracy: 66.00%\n",
      "34\tValidation loss: 1.2133\tBest loss: 1.2133\tAccuracy: 67.33%\n",
      "35\tValidation loss: 1.2045\tBest loss: 1.2045\tAccuracy: 70.00%\n",
      "36\tValidation loss: 1.1969\tBest loss: 1.1969\tAccuracy: 70.67%\n",
      "37\tValidation loss: 1.1900\tBest loss: 1.1900\tAccuracy: 70.67%\n",
      "38\tValidation loss: 1.1840\tBest loss: 1.1840\tAccuracy: 71.33%\n",
      "39\tValidation loss: 1.1789\tBest loss: 1.1789\tAccuracy: 71.33%\n",
      "40\tValidation loss: 1.1747\tBest loss: 1.1747\tAccuracy: 72.00%\n",
      "41\tValidation loss: 1.1715\tBest loss: 1.1715\tAccuracy: 71.33%\n",
      "42\tValidation loss: 1.1692\tBest loss: 1.1692\tAccuracy: 73.33%\n",
      "43\tValidation loss: 1.1674\tBest loss: 1.1674\tAccuracy: 74.00%\n",
      "44\tValidation loss: 1.1655\tBest loss: 1.1655\tAccuracy: 74.00%\n",
      "45\tValidation loss: 1.1629\tBest loss: 1.1629\tAccuracy: 74.67%\n",
      "46\tValidation loss: 1.1596\tBest loss: 1.1596\tAccuracy: 74.67%\n",
      "47\tValidation loss: 1.1557\tBest loss: 1.1557\tAccuracy: 75.33%\n",
      "48\tValidation loss: 1.1517\tBest loss: 1.1517\tAccuracy: 76.67%\n",
      "49\tValidation loss: 1.1479\tBest loss: 1.1479\tAccuracy: 77.33%\n",
      "50\tValidation loss: 1.1448\tBest loss: 1.1448\tAccuracy: 78.00%\n",
      "51\tValidation loss: 1.1424\tBest loss: 1.1424\tAccuracy: 78.67%\n",
      "52\tValidation loss: 1.1408\tBest loss: 1.1408\tAccuracy: 78.00%\n",
      "53\tValidation loss: 1.1398\tBest loss: 1.1398\tAccuracy: 78.00%\n",
      "54\tValidation loss: 1.1394\tBest loss: 1.1394\tAccuracy: 77.33%\n",
      "55\tValidation loss: 1.1394\tBest loss: 1.1394\tAccuracy: 77.33%\n",
      "56\tValidation loss: 1.1397\tBest loss: 1.1394\tAccuracy: 76.67%\n",
      "57\tValidation loss: 1.1403\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "58\tValidation loss: 1.1411\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "59\tValidation loss: 1.1420\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "60\tValidation loss: 1.1426\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "61\tValidation loss: 1.1428\tBest loss: 1.1394\tAccuracy: 77.33%\n",
      "62\tValidation loss: 1.1421\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "63\tValidation loss: 1.1408\tBest loss: 1.1394\tAccuracy: 77.33%\n",
      "64\tValidation loss: 1.1390\tBest loss: 1.1390\tAccuracy: 77.33%\n",
      "65\tValidation loss: 1.1370\tBest loss: 1.1370\tAccuracy: 78.00%\n",
      "66\tValidation loss: 1.1350\tBest loss: 1.1350\tAccuracy: 77.33%\n",
      "67\tValidation loss: 1.1332\tBest loss: 1.1332\tAccuracy: 77.33%\n",
      "68\tValidation loss: 1.1317\tBest loss: 1.1317\tAccuracy: 77.33%\n",
      "69\tValidation loss: 1.1305\tBest loss: 1.1305\tAccuracy: 78.00%\n",
      "70\tValidation loss: 1.1297\tBest loss: 1.1297\tAccuracy: 78.67%\n",
      "71\tValidation loss: 1.1294\tBest loss: 1.1294\tAccuracy: 78.67%\n",
      "72\tValidation loss: 1.1296\tBest loss: 1.1294\tAccuracy: 79.33%\n",
      "73\tValidation loss: 1.1300\tBest loss: 1.1294\tAccuracy: 78.67%\n",
      "74\tValidation loss: 1.1305\tBest loss: 1.1294\tAccuracy: 78.67%\n",
      "75\tValidation loss: 1.1308\tBest loss: 1.1294\tAccuracy: 78.67%\n",
      "76\tValidation loss: 1.1308\tBest loss: 1.1294\tAccuracy: 78.00%\n",
      "77\tValidation loss: 1.1303\tBest loss: 1.1294\tAccuracy: 78.00%\n",
      "78\tValidation loss: 1.1295\tBest loss: 1.1294\tAccuracy: 78.00%\n",
      "79\tValidation loss: 1.1284\tBest loss: 1.1284\tAccuracy: 78.67%\n",
      "80\tValidation loss: 1.1271\tBest loss: 1.1271\tAccuracy: 78.67%\n",
      "81\tValidation loss: 1.1259\tBest loss: 1.1259\tAccuracy: 78.67%\n",
      "82\tValidation loss: 1.1249\tBest loss: 1.1249\tAccuracy: 78.00%\n",
      "83\tValidation loss: 1.1241\tBest loss: 1.1241\tAccuracy: 78.00%\n",
      "84\tValidation loss: 1.1236\tBest loss: 1.1236\tAccuracy: 78.00%\n",
      "85\tValidation loss: 1.1234\tBest loss: 1.1234\tAccuracy: 77.33%\n",
      "86\tValidation loss: 1.1233\tBest loss: 1.1233\tAccuracy: 78.00%\n",
      "87\tValidation loss: 1.1230\tBest loss: 1.1230\tAccuracy: 78.00%\n",
      "88\tValidation loss: 1.1224\tBest loss: 1.1224\tAccuracy: 78.00%\n",
      "89\tValidation loss: 1.1213\tBest loss: 1.1213\tAccuracy: 78.00%\n",
      "90\tValidation loss: 1.1196\tBest loss: 1.1196\tAccuracy: 78.00%\n",
      "91\tValidation loss: 1.1174\tBest loss: 1.1174\tAccuracy: 78.00%\n",
      "92\tValidation loss: 1.1148\tBest loss: 1.1148\tAccuracy: 78.67%\n",
      "93\tValidation loss: 1.1117\tBest loss: 1.1117\tAccuracy: 79.33%\n",
      "94\tValidation loss: 1.1083\tBest loss: 1.1083\tAccuracy: 80.67%\n",
      "95\tValidation loss: 1.1041\tBest loss: 1.1041\tAccuracy: 80.67%\n",
      "96\tValidation loss: 1.0995\tBest loss: 1.0995\tAccuracy: 82.00%\n",
      "97\tValidation loss: 1.0950\tBest loss: 1.0950\tAccuracy: 82.67%\n",
      "98\tValidation loss: 1.0914\tBest loss: 1.0914\tAccuracy: 83.33%\n",
      "99\tValidation loss: 1.0895\tBest loss: 1.0895\tAccuracy: 82.67%\n",
      "100\tValidation loss: 1.0893\tBest loss: 1.0893\tAccuracy: 83.33%\n",
      "101\tValidation loss: 1.0899\tBest loss: 1.0893\tAccuracy: 83.33%\n",
      "102\tValidation loss: 1.0902\tBest loss: 1.0893\tAccuracy: 82.67%\n",
      "103\tValidation loss: 1.0895\tBest loss: 1.0893\tAccuracy: 82.67%\n",
      "104\tValidation loss: 1.0876\tBest loss: 1.0876\tAccuracy: 82.67%\n",
      "105\tValidation loss: 1.0848\tBest loss: 1.0848\tAccuracy: 82.67%\n",
      "106\tValidation loss: 1.0819\tBest loss: 1.0819\tAccuracy: 82.67%\n",
      "107\tValidation loss: 1.0795\tBest loss: 1.0795\tAccuracy: 84.00%\n",
      "108\tValidation loss: 1.0780\tBest loss: 1.0780\tAccuracy: 84.00%\n",
      "109\tValidation loss: 1.0776\tBest loss: 1.0776\tAccuracy: 84.67%\n",
      "110\tValidation loss: 1.0779\tBest loss: 1.0776\tAccuracy: 84.67%\n",
      "111\tValidation loss: 1.0784\tBest loss: 1.0776\tAccuracy: 83.33%\n",
      "112\tValidation loss: 1.0785\tBest loss: 1.0776\tAccuracy: 83.33%\n",
      "113\tValidation loss: 1.0783\tBest loss: 1.0776\tAccuracy: 83.33%\n",
      "114\tValidation loss: 1.0778\tBest loss: 1.0776\tAccuracy: 84.67%\n",
      "115\tValidation loss: 1.0775\tBest loss: 1.0775\tAccuracy: 84.67%\n",
      "116\tValidation loss: 1.0774\tBest loss: 1.0774\tAccuracy: 84.67%\n",
      "117\tValidation loss: 1.0773\tBest loss: 1.0773\tAccuracy: 83.33%\n",
      "118\tValidation loss: 1.0769\tBest loss: 1.0769\tAccuracy: 83.33%\n",
      "119\tValidation loss: 1.0760\tBest loss: 1.0760\tAccuracy: 83.33%\n",
      "120\tValidation loss: 1.0746\tBest loss: 1.0746\tAccuracy: 84.00%\n",
      "121\tValidation loss: 1.0727\tBest loss: 1.0727\tAccuracy: 84.67%\n",
      "122\tValidation loss: 1.0706\tBest loss: 1.0706\tAccuracy: 84.67%\n",
      "123\tValidation loss: 1.0688\tBest loss: 1.0688\tAccuracy: 84.67%\n",
      "124\tValidation loss: 1.0674\tBest loss: 1.0674\tAccuracy: 85.33%\n",
      "125\tValidation loss: 1.0666\tBest loss: 1.0666\tAccuracy: 85.33%\n",
      "126\tValidation loss: 1.0663\tBest loss: 1.0663\tAccuracy: 85.33%\n",
      "127\tValidation loss: 1.0663\tBest loss: 1.0663\tAccuracy: 85.33%\n",
      "128\tValidation loss: 1.0666\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "129\tValidation loss: 1.0669\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "130\tValidation loss: 1.0672\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "131\tValidation loss: 1.0672\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "132\tValidation loss: 1.0671\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "133\tValidation loss: 1.0668\tBest loss: 1.0663\tAccuracy: 85.33%\n",
      "134\tValidation loss: 1.0664\tBest loss: 1.0663\tAccuracy: 85.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\tValidation loss: 1.0662\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "136\tValidation loss: 1.0662\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "137\tValidation loss: 1.0663\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "138\tValidation loss: 1.0667\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "139\tValidation loss: 1.0672\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "140\tValidation loss: 1.0677\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "141\tValidation loss: 1.0681\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "142\tValidation loss: 1.0684\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "143\tValidation loss: 1.0684\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "144\tValidation loss: 1.0682\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "145\tValidation loss: 1.0678\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "146\tValidation loss: 1.0674\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "147\tValidation loss: 1.0671\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "148\tValidation loss: 1.0669\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "149\tValidation loss: 1.0670\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "150\tValidation loss: 1.0672\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "151\tValidation loss: 1.0674\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "152\tValidation loss: 1.0677\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "153\tValidation loss: 1.0679\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "154\tValidation loss: 1.0681\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "155\tValidation loss: 1.0682\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "156\tValidation loss: 1.0683\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "early stop\n",
      "INFO:tensorflow:Restoring parameters from Team58_HW3_1\\Team58_HW3_1.ckpt\n",
      "test accuracy 82.6990306377 %\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "## parameter setting ##\n",
    "n_epochs = 1000\n",
    "early_stop_max_steps = 20\n",
    "steps_without_progress = 0\n",
    "best_loss = 9999999\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"Team58_HW2\\Team58_HW2.ckpt\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: X_train2, y: y_train2})\n",
    "        now_loss = sess.run(loss, feed_dict={X: X_valid2, y: y_valid2})\n",
    "        now_acc = sess.run(accuracy, feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "        ## early stop implementation ##\n",
    "        if now_loss < best_loss:\n",
    "            HW3_1_saver.save(sess, \"Team58_HW3_1\\Team58_HW3_1.ckpt\")\n",
    "            best_loss = now_loss\n",
    "            steps_without_progress = 0\n",
    "        else:\n",
    "            steps_without_progress += 1\n",
    "            if steps_without_progress > early_stop_max_steps: ## if no progress in 20 step then early stop ##\n",
    "                print(\"early stop\")\n",
    "                break \n",
    "        ## print result per epoch ##\n",
    "        print(\"{}\\tValidation loss: {:.4f}\\tBest loss: {:.4f}\\tAccuracy: {:.2f}%\".format(epoch, now_loss, best_loss, now_acc * 100))\n",
    "\n",
    "    HW3_1_saver.restore(sess, \"Team58_HW3_1\\Team58_HW3_1.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"test accuracy\",acc_test * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Team58_HW2\\Team58_HW2.ckpt\n",
      "training time 2.527967691421509 s\n"
     ]
    }
   ],
   "source": [
    "## Measure training time = 2.53 s ##\n",
    "## train 1000 epochs without early stop\n",
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"Team58_HW2\\Team58_HW2.ckpt\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    ## timer start ##\n",
    "    tStart = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: X_train2, y: y_train2})\n",
    "    \n",
    "    ## timer end ##\n",
    "    tEnd = time.time()\n",
    "    \n",
    "    print(\"training time\",tEnd - tStart,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3-2 cache 5th layer -- training time: 5.30s, accuracy:82.70% ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Team58_HW2\\Team58_HW2.ckpt\n",
      "0\tValidation loss: 1.5964\tBest loss: 1.5964\tAccuracy: 26.67%\n",
      "1\tValidation loss: 1.5050\tBest loss: 1.5050\tAccuracy: 40.00%\n",
      "2\tValidation loss: 1.4554\tBest loss: 1.4554\tAccuracy: 44.00%\n",
      "3\tValidation loss: 1.4194\tBest loss: 1.4194\tAccuracy: 49.33%\n",
      "4\tValidation loss: 1.3876\tBest loss: 1.3876\tAccuracy: 50.67%\n",
      "5\tValidation loss: 1.3605\tBest loss: 1.3605\tAccuracy: 54.67%\n",
      "6\tValidation loss: 1.3437\tBest loss: 1.3437\tAccuracy: 56.00%\n",
      "7\tValidation loss: 1.3365\tBest loss: 1.3365\tAccuracy: 56.67%\n",
      "8\tValidation loss: 1.3361\tBest loss: 1.3361\tAccuracy: 57.33%\n",
      "9\tValidation loss: 1.3348\tBest loss: 1.3348\tAccuracy: 58.00%\n",
      "10\tValidation loss: 1.3298\tBest loss: 1.3298\tAccuracy: 57.33%\n",
      "11\tValidation loss: 1.3221\tBest loss: 1.3221\tAccuracy: 59.33%\n",
      "12\tValidation loss: 1.3148\tBest loss: 1.3148\tAccuracy: 59.33%\n",
      "13\tValidation loss: 1.3091\tBest loss: 1.3091\tAccuracy: 58.67%\n",
      "14\tValidation loss: 1.3037\tBest loss: 1.3037\tAccuracy: 58.00%\n",
      "15\tValidation loss: 1.2978\tBest loss: 1.2978\tAccuracy: 58.00%\n",
      "16\tValidation loss: 1.2915\tBest loss: 1.2915\tAccuracy: 58.00%\n",
      "17\tValidation loss: 1.2854\tBest loss: 1.2854\tAccuracy: 60.00%\n",
      "18\tValidation loss: 1.2803\tBest loss: 1.2803\tAccuracy: 60.67%\n",
      "19\tValidation loss: 1.2773\tBest loss: 1.2773\tAccuracy: 59.33%\n",
      "20\tValidation loss: 1.2766\tBest loss: 1.2766\tAccuracy: 61.33%\n",
      "21\tValidation loss: 1.2769\tBest loss: 1.2766\tAccuracy: 61.33%\n",
      "22\tValidation loss: 1.2771\tBest loss: 1.2766\tAccuracy: 60.67%\n",
      "23\tValidation loss: 1.2749\tBest loss: 1.2749\tAccuracy: 60.00%\n",
      "24\tValidation loss: 1.2701\tBest loss: 1.2701\tAccuracy: 62.00%\n",
      "25\tValidation loss: 1.2643\tBest loss: 1.2643\tAccuracy: 62.00%\n",
      "26\tValidation loss: 1.2585\tBest loss: 1.2585\tAccuracy: 61.33%\n",
      "27\tValidation loss: 1.2534\tBest loss: 1.2534\tAccuracy: 63.33%\n",
      "28\tValidation loss: 1.2489\tBest loss: 1.2489\tAccuracy: 64.67%\n",
      "29\tValidation loss: 1.2443\tBest loss: 1.2443\tAccuracy: 65.33%\n",
      "30\tValidation loss: 1.2391\tBest loss: 1.2391\tAccuracy: 65.33%\n",
      "31\tValidation loss: 1.2340\tBest loss: 1.2340\tAccuracy: 64.67%\n",
      "32\tValidation loss: 1.2288\tBest loss: 1.2288\tAccuracy: 65.33%\n",
      "33\tValidation loss: 1.2221\tBest loss: 1.2221\tAccuracy: 66.00%\n",
      "34\tValidation loss: 1.2133\tBest loss: 1.2133\tAccuracy: 67.33%\n",
      "35\tValidation loss: 1.2045\tBest loss: 1.2045\tAccuracy: 70.00%\n",
      "36\tValidation loss: 1.1969\tBest loss: 1.1969\tAccuracy: 70.67%\n",
      "37\tValidation loss: 1.1900\tBest loss: 1.1900\tAccuracy: 70.67%\n",
      "38\tValidation loss: 1.1840\tBest loss: 1.1840\tAccuracy: 71.33%\n",
      "39\tValidation loss: 1.1789\tBest loss: 1.1789\tAccuracy: 71.33%\n",
      "40\tValidation loss: 1.1747\tBest loss: 1.1747\tAccuracy: 72.00%\n",
      "41\tValidation loss: 1.1715\tBest loss: 1.1715\tAccuracy: 71.33%\n",
      "42\tValidation loss: 1.1692\tBest loss: 1.1692\tAccuracy: 73.33%\n",
      "43\tValidation loss: 1.1674\tBest loss: 1.1674\tAccuracy: 74.00%\n",
      "44\tValidation loss: 1.1655\tBest loss: 1.1655\tAccuracy: 74.00%\n",
      "45\tValidation loss: 1.1629\tBest loss: 1.1629\tAccuracy: 74.67%\n",
      "46\tValidation loss: 1.1596\tBest loss: 1.1596\tAccuracy: 74.67%\n",
      "47\tValidation loss: 1.1557\tBest loss: 1.1557\tAccuracy: 75.33%\n",
      "48\tValidation loss: 1.1517\tBest loss: 1.1517\tAccuracy: 76.67%\n",
      "49\tValidation loss: 1.1479\tBest loss: 1.1479\tAccuracy: 77.33%\n",
      "50\tValidation loss: 1.1448\tBest loss: 1.1448\tAccuracy: 78.00%\n",
      "51\tValidation loss: 1.1424\tBest loss: 1.1424\tAccuracy: 78.67%\n",
      "52\tValidation loss: 1.1408\tBest loss: 1.1408\tAccuracy: 78.00%\n",
      "53\tValidation loss: 1.1398\tBest loss: 1.1398\tAccuracy: 78.00%\n",
      "54\tValidation loss: 1.1394\tBest loss: 1.1394\tAccuracy: 77.33%\n",
      "55\tValidation loss: 1.1394\tBest loss: 1.1394\tAccuracy: 77.33%\n",
      "56\tValidation loss: 1.1397\tBest loss: 1.1394\tAccuracy: 76.67%\n",
      "57\tValidation loss: 1.1403\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "58\tValidation loss: 1.1411\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "59\tValidation loss: 1.1420\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "60\tValidation loss: 1.1426\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "61\tValidation loss: 1.1428\tBest loss: 1.1394\tAccuracy: 77.33%\n",
      "62\tValidation loss: 1.1421\tBest loss: 1.1394\tAccuracy: 78.00%\n",
      "63\tValidation loss: 1.1408\tBest loss: 1.1394\tAccuracy: 77.33%\n",
      "64\tValidation loss: 1.1390\tBest loss: 1.1390\tAccuracy: 77.33%\n",
      "65\tValidation loss: 1.1370\tBest loss: 1.1370\tAccuracy: 78.00%\n",
      "66\tValidation loss: 1.1350\tBest loss: 1.1350\tAccuracy: 77.33%\n",
      "67\tValidation loss: 1.1332\tBest loss: 1.1332\tAccuracy: 77.33%\n",
      "68\tValidation loss: 1.1317\tBest loss: 1.1317\tAccuracy: 77.33%\n",
      "69\tValidation loss: 1.1305\tBest loss: 1.1305\tAccuracy: 78.00%\n",
      "70\tValidation loss: 1.1297\tBest loss: 1.1297\tAccuracy: 78.67%\n",
      "71\tValidation loss: 1.1294\tBest loss: 1.1294\tAccuracy: 78.67%\n",
      "72\tValidation loss: 1.1296\tBest loss: 1.1294\tAccuracy: 79.33%\n",
      "73\tValidation loss: 1.1300\tBest loss: 1.1294\tAccuracy: 78.67%\n",
      "74\tValidation loss: 1.1305\tBest loss: 1.1294\tAccuracy: 78.67%\n",
      "75\tValidation loss: 1.1308\tBest loss: 1.1294\tAccuracy: 78.67%\n",
      "76\tValidation loss: 1.1308\tBest loss: 1.1294\tAccuracy: 78.00%\n",
      "77\tValidation loss: 1.1303\tBest loss: 1.1294\tAccuracy: 78.00%\n",
      "78\tValidation loss: 1.1295\tBest loss: 1.1294\tAccuracy: 78.00%\n",
      "79\tValidation loss: 1.1284\tBest loss: 1.1284\tAccuracy: 78.67%\n",
      "80\tValidation loss: 1.1271\tBest loss: 1.1271\tAccuracy: 78.67%\n",
      "81\tValidation loss: 1.1259\tBest loss: 1.1259\tAccuracy: 78.67%\n",
      "82\tValidation loss: 1.1249\tBest loss: 1.1249\tAccuracy: 78.00%\n",
      "83\tValidation loss: 1.1241\tBest loss: 1.1241\tAccuracy: 78.00%\n",
      "84\tValidation loss: 1.1236\tBest loss: 1.1236\tAccuracy: 78.00%\n",
      "85\tValidation loss: 1.1234\tBest loss: 1.1234\tAccuracy: 77.33%\n",
      "86\tValidation loss: 1.1233\tBest loss: 1.1233\tAccuracy: 78.00%\n",
      "87\tValidation loss: 1.1230\tBest loss: 1.1230\tAccuracy: 78.00%\n",
      "88\tValidation loss: 1.1224\tBest loss: 1.1224\tAccuracy: 78.00%\n",
      "89\tValidation loss: 1.1213\tBest loss: 1.1213\tAccuracy: 78.00%\n",
      "90\tValidation loss: 1.1196\tBest loss: 1.1196\tAccuracy: 78.00%\n",
      "91\tValidation loss: 1.1174\tBest loss: 1.1174\tAccuracy: 78.00%\n",
      "92\tValidation loss: 1.1148\tBest loss: 1.1148\tAccuracy: 78.67%\n",
      "93\tValidation loss: 1.1117\tBest loss: 1.1117\tAccuracy: 79.33%\n",
      "94\tValidation loss: 1.1083\tBest loss: 1.1083\tAccuracy: 80.67%\n",
      "95\tValidation loss: 1.1041\tBest loss: 1.1041\tAccuracy: 80.67%\n",
      "96\tValidation loss: 1.0995\tBest loss: 1.0995\tAccuracy: 82.00%\n",
      "97\tValidation loss: 1.0950\tBest loss: 1.0950\tAccuracy: 82.67%\n",
      "98\tValidation loss: 1.0914\tBest loss: 1.0914\tAccuracy: 83.33%\n",
      "99\tValidation loss: 1.0895\tBest loss: 1.0895\tAccuracy: 82.67%\n",
      "100\tValidation loss: 1.0893\tBest loss: 1.0893\tAccuracy: 83.33%\n",
      "101\tValidation loss: 1.0899\tBest loss: 1.0893\tAccuracy: 83.33%\n",
      "102\tValidation loss: 1.0902\tBest loss: 1.0893\tAccuracy: 82.67%\n",
      "103\tValidation loss: 1.0895\tBest loss: 1.0893\tAccuracy: 82.67%\n",
      "104\tValidation loss: 1.0876\tBest loss: 1.0876\tAccuracy: 82.67%\n",
      "105\tValidation loss: 1.0848\tBest loss: 1.0848\tAccuracy: 82.67%\n",
      "106\tValidation loss: 1.0819\tBest loss: 1.0819\tAccuracy: 82.67%\n",
      "107\tValidation loss: 1.0795\tBest loss: 1.0795\tAccuracy: 84.00%\n",
      "108\tValidation loss: 1.0780\tBest loss: 1.0780\tAccuracy: 84.00%\n",
      "109\tValidation loss: 1.0776\tBest loss: 1.0776\tAccuracy: 84.67%\n",
      "110\tValidation loss: 1.0779\tBest loss: 1.0776\tAccuracy: 84.67%\n",
      "111\tValidation loss: 1.0784\tBest loss: 1.0776\tAccuracy: 83.33%\n",
      "112\tValidation loss: 1.0785\tBest loss: 1.0776\tAccuracy: 83.33%\n",
      "113\tValidation loss: 1.0783\tBest loss: 1.0776\tAccuracy: 83.33%\n",
      "114\tValidation loss: 1.0778\tBest loss: 1.0776\tAccuracy: 84.67%\n",
      "115\tValidation loss: 1.0775\tBest loss: 1.0775\tAccuracy: 84.67%\n",
      "116\tValidation loss: 1.0774\tBest loss: 1.0774\tAccuracy: 84.67%\n",
      "117\tValidation loss: 1.0773\tBest loss: 1.0773\tAccuracy: 83.33%\n",
      "118\tValidation loss: 1.0769\tBest loss: 1.0769\tAccuracy: 83.33%\n",
      "119\tValidation loss: 1.0760\tBest loss: 1.0760\tAccuracy: 83.33%\n",
      "120\tValidation loss: 1.0746\tBest loss: 1.0746\tAccuracy: 84.00%\n",
      "121\tValidation loss: 1.0727\tBest loss: 1.0727\tAccuracy: 84.67%\n",
      "122\tValidation loss: 1.0706\tBest loss: 1.0706\tAccuracy: 84.67%\n",
      "123\tValidation loss: 1.0688\tBest loss: 1.0688\tAccuracy: 84.67%\n",
      "124\tValidation loss: 1.0674\tBest loss: 1.0674\tAccuracy: 85.33%\n",
      "125\tValidation loss: 1.0666\tBest loss: 1.0666\tAccuracy: 85.33%\n",
      "126\tValidation loss: 1.0663\tBest loss: 1.0663\tAccuracy: 85.33%\n",
      "127\tValidation loss: 1.0663\tBest loss: 1.0663\tAccuracy: 85.33%\n",
      "128\tValidation loss: 1.0666\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "129\tValidation loss: 1.0669\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "130\tValidation loss: 1.0672\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "131\tValidation loss: 1.0672\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "132\tValidation loss: 1.0671\tBest loss: 1.0663\tAccuracy: 86.00%\n",
      "133\tValidation loss: 1.0668\tBest loss: 1.0663\tAccuracy: 85.33%\n",
      "134\tValidation loss: 1.0664\tBest loss: 1.0663\tAccuracy: 85.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\tValidation loss: 1.0662\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "136\tValidation loss: 1.0662\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "137\tValidation loss: 1.0663\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "138\tValidation loss: 1.0667\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "139\tValidation loss: 1.0672\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "140\tValidation loss: 1.0677\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "141\tValidation loss: 1.0681\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "142\tValidation loss: 1.0684\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "143\tValidation loss: 1.0684\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "144\tValidation loss: 1.0682\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "145\tValidation loss: 1.0678\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "146\tValidation loss: 1.0674\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "147\tValidation loss: 1.0671\tBest loss: 1.0662\tAccuracy: 85.33%\n",
      "148\tValidation loss: 1.0669\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "149\tValidation loss: 1.0670\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "150\tValidation loss: 1.0672\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "151\tValidation loss: 1.0674\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "152\tValidation loss: 1.0677\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "153\tValidation loss: 1.0679\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "154\tValidation loss: 1.0681\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "155\tValidation loss: 1.0682\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "156\tValidation loss: 1.0683\tBest loss: 1.0662\tAccuracy: 84.67%\n",
      "early stop\n",
      "INFO:tensorflow:Restoring parameters from Team58_HW3_2\\Team58_HW3_2.ckpt\n",
      "test accuracy 82.6990306377 %\n"
     ]
    }
   ],
   "source": [
    "## get layer5 tensor ##\n",
    "layer5_out = tf.get_default_graph().get_tensor_by_name(\"layer5/Elu:0\")\n",
    "HW3_2_saver = tf.train.Saver()\n",
    "import time\n",
    "\n",
    "## parameter setting ##\n",
    "n_epochs = 1000\n",
    "early_stop_max_steps = 20\n",
    "steps_without_progress = 0\n",
    "best_loss = 9999999\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"Team58_HW2\\Team58_HW2.ckpt\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    ## cache layer5 output ##\n",
    "    layer5_train = layer5_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
    "    layer5_valid = layer5_out.eval(feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={layer5_out: layer5_train, y: y_train2})\n",
    "        now_loss = sess.run(loss, feed_dict={X: X_valid2, y: y_valid2})\n",
    "        now_acc = sess.run(accuracy, feed_dict={X: X_valid2, y: y_valid2})\n",
    "        ## early stop implementation ##\n",
    "        if now_loss < best_loss:\n",
    "            HW3_2_saver.save(sess, \"Team58_HW3_2\\Team58_HW3_2.ckpt\")\n",
    "            best_loss = now_loss\n",
    "            steps_without_progress = 0\n",
    "        else:\n",
    "            steps_without_progress += 1\n",
    "            if steps_without_progress > early_stop_max_steps: ## if no progress in 20 step then early stop ##\n",
    "                print(\"early stop\")\n",
    "                break\n",
    "        ## print result per epoch ##\n",
    "        print(\"{}\\tValidation loss: {:.4f}\\tBest loss: {:.4f}\\tAccuracy: {:.2f}%\".format(epoch, now_loss, best_loss, now_acc * 100))\n",
    "\n",
    "    \n",
    "    HW3_1_saver.restore(sess, \"Team58_HW3_2\\Team58_HW3_2.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"test accuracy\",acc_test * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Team58_HW2\\Team58_HW2.ckpt\n",
      "training time 2.229403018951416 s\n"
     ]
    }
   ],
   "source": [
    "## Measure training time = 2.23 s, faster than HW3.1 ##\n",
    "## train 1000 epochs without early stop\n",
    "layer5_out = tf.get_default_graph().get_tensor_by_name(\"layer5/Elu:0\")\n",
    "HW3_2_saver = tf.train.Saver()\n",
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"Team58_HW2\\Team58_HW2.ckpt\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()    \n",
    "    ## cache layer5 output ##\n",
    "    layer5_train = layer5_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
    "    \n",
    "    ## timer begin ##\n",
    "    tStart = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={layer5_out: layer5_train, y: y_train2})\n",
    "    ## timer end ##\n",
    "    tEnd = time.time()\n",
    "    print(\"training time\",tEnd - tStart,\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3-3 4 layers instead, accuracy: 84.84% , better than HW1&HW2(82.70%) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import variance_scaling_initializer\n",
    "he_init = variance_scaling_initializer()\n",
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"Team58_HW2\\Team58_HW2.ckpt.meta\")\n",
    "\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "## get 4th layer output before training ##\n",
    "layer4_out = tf.get_default_graph().get_tensor_by_name(\"layer4/Elu:0\")\n",
    "# add a new softmax layer\n",
    "logits = tf.layers.dense(layer4_out, 5, kernel_initializer=he_init, name=\"layer4_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "## setting trainable variable ##\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"layer4_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(0.01, name=\"Adamgram\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "HW3_3_saver = tf.train.Saver() ## creat saver ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Team58_HW2\\Team58_HW2.ckpt\n",
      "0\tValidation loss: 1.3320\tBest loss: 1.3320\tAccuracy: 45.33%\n",
      "1\tValidation loss: 1.1499\tBest loss: 1.1499\tAccuracy: 59.33%\n",
      "2\tValidation loss: 1.1539\tBest loss: 1.1499\tAccuracy: 54.67%\n",
      "3\tValidation loss: 1.1299\tBest loss: 1.1299\tAccuracy: 54.00%\n",
      "4\tValidation loss: 1.0490\tBest loss: 1.0490\tAccuracy: 58.67%\n",
      "5\tValidation loss: 0.9647\tBest loss: 0.9647\tAccuracy: 62.67%\n",
      "6\tValidation loss: 0.9276\tBest loss: 0.9276\tAccuracy: 68.00%\n",
      "7\tValidation loss: 0.9401\tBest loss: 0.9276\tAccuracy: 66.67%\n",
      "8\tValidation loss: 0.9670\tBest loss: 0.9276\tAccuracy: 67.33%\n",
      "9\tValidation loss: 0.9773\tBest loss: 0.9276\tAccuracy: 66.67%\n",
      "10\tValidation loss: 0.9611\tBest loss: 0.9276\tAccuracy: 68.67%\n",
      "11\tValidation loss: 0.9249\tBest loss: 0.9249\tAccuracy: 70.00%\n",
      "12\tValidation loss: 0.8828\tBest loss: 0.8828\tAccuracy: 71.33%\n",
      "13\tValidation loss: 0.8471\tBest loss: 0.8471\tAccuracy: 72.00%\n",
      "14\tValidation loss: 0.8226\tBest loss: 0.8226\tAccuracy: 72.00%\n",
      "15\tValidation loss: 0.8071\tBest loss: 0.8071\tAccuracy: 73.33%\n",
      "16\tValidation loss: 0.7947\tBest loss: 0.7947\tAccuracy: 75.33%\n",
      "17\tValidation loss: 0.7804\tBest loss: 0.7804\tAccuracy: 76.00%\n",
      "18\tValidation loss: 0.7625\tBest loss: 0.7625\tAccuracy: 76.00%\n",
      "19\tValidation loss: 0.7428\tBest loss: 0.7428\tAccuracy: 77.33%\n",
      "20\tValidation loss: 0.7239\tBest loss: 0.7239\tAccuracy: 76.00%\n",
      "21\tValidation loss: 0.7079\tBest loss: 0.7079\tAccuracy: 77.33%\n",
      "22\tValidation loss: 0.6953\tBest loss: 0.6953\tAccuracy: 75.33%\n",
      "23\tValidation loss: 0.6849\tBest loss: 0.6849\tAccuracy: 75.33%\n",
      "24\tValidation loss: 0.6751\tBest loss: 0.6751\tAccuracy: 75.33%\n",
      "25\tValidation loss: 0.6643\tBest loss: 0.6643\tAccuracy: 74.67%\n",
      "26\tValidation loss: 0.6514\tBest loss: 0.6514\tAccuracy: 76.67%\n",
      "27\tValidation loss: 0.6366\tBest loss: 0.6366\tAccuracy: 76.67%\n",
      "28\tValidation loss: 0.6210\tBest loss: 0.6210\tAccuracy: 77.33%\n",
      "29\tValidation loss: 0.6058\tBest loss: 0.6058\tAccuracy: 79.33%\n",
      "30\tValidation loss: 0.5915\tBest loss: 0.5915\tAccuracy: 82.00%\n",
      "31\tValidation loss: 0.5782\tBest loss: 0.5782\tAccuracy: 82.67%\n",
      "32\tValidation loss: 0.5658\tBest loss: 0.5658\tAccuracy: 82.67%\n",
      "33\tValidation loss: 0.5544\tBest loss: 0.5544\tAccuracy: 83.33%\n",
      "34\tValidation loss: 0.5446\tBest loss: 0.5446\tAccuracy: 83.33%\n",
      "35\tValidation loss: 0.5369\tBest loss: 0.5369\tAccuracy: 83.33%\n",
      "36\tValidation loss: 0.5314\tBest loss: 0.5314\tAccuracy: 82.67%\n",
      "37\tValidation loss: 0.5279\tBest loss: 0.5279\tAccuracy: 82.67%\n",
      "38\tValidation loss: 0.5255\tBest loss: 0.5255\tAccuracy: 81.33%\n",
      "39\tValidation loss: 0.5236\tBest loss: 0.5236\tAccuracy: 81.33%\n",
      "40\tValidation loss: 0.5217\tBest loss: 0.5217\tAccuracy: 81.33%\n",
      "41\tValidation loss: 0.5196\tBest loss: 0.5196\tAccuracy: 82.00%\n",
      "42\tValidation loss: 0.5173\tBest loss: 0.5173\tAccuracy: 82.00%\n",
      "43\tValidation loss: 0.5149\tBest loss: 0.5149\tAccuracy: 84.00%\n",
      "44\tValidation loss: 0.5124\tBest loss: 0.5124\tAccuracy: 84.00%\n",
      "45\tValidation loss: 0.5098\tBest loss: 0.5098\tAccuracy: 84.00%\n",
      "46\tValidation loss: 0.5071\tBest loss: 0.5071\tAccuracy: 82.67%\n",
      "47\tValidation loss: 0.5045\tBest loss: 0.5045\tAccuracy: 82.00%\n",
      "48\tValidation loss: 0.5019\tBest loss: 0.5019\tAccuracy: 82.67%\n",
      "49\tValidation loss: 0.4997\tBest loss: 0.4997\tAccuracy: 82.67%\n",
      "50\tValidation loss: 0.4977\tBest loss: 0.4977\tAccuracy: 82.67%\n",
      "51\tValidation loss: 0.4960\tBest loss: 0.4960\tAccuracy: 82.67%\n",
      "52\tValidation loss: 0.4944\tBest loss: 0.4944\tAccuracy: 82.67%\n",
      "53\tValidation loss: 0.4927\tBest loss: 0.4927\tAccuracy: 83.33%\n",
      "54\tValidation loss: 0.4909\tBest loss: 0.4909\tAccuracy: 83.33%\n",
      "55\tValidation loss: 0.4888\tBest loss: 0.4888\tAccuracy: 83.33%\n",
      "56\tValidation loss: 0.4863\tBest loss: 0.4863\tAccuracy: 84.00%\n",
      "57\tValidation loss: 0.4836\tBest loss: 0.4836\tAccuracy: 84.67%\n",
      "58\tValidation loss: 0.4808\tBest loss: 0.4808\tAccuracy: 84.00%\n",
      "59\tValidation loss: 0.4779\tBest loss: 0.4779\tAccuracy: 84.00%\n",
      "60\tValidation loss: 0.4752\tBest loss: 0.4752\tAccuracy: 84.00%\n",
      "61\tValidation loss: 0.4727\tBest loss: 0.4727\tAccuracy: 84.00%\n",
      "62\tValidation loss: 0.4705\tBest loss: 0.4705\tAccuracy: 84.00%\n",
      "63\tValidation loss: 0.4686\tBest loss: 0.4686\tAccuracy: 84.00%\n",
      "64\tValidation loss: 0.4670\tBest loss: 0.4670\tAccuracy: 84.00%\n",
      "65\tValidation loss: 0.4657\tBest loss: 0.4657\tAccuracy: 84.00%\n",
      "66\tValidation loss: 0.4645\tBest loss: 0.4645\tAccuracy: 84.00%\n",
      "67\tValidation loss: 0.4634\tBest loss: 0.4634\tAccuracy: 84.00%\n",
      "68\tValidation loss: 0.4623\tBest loss: 0.4623\tAccuracy: 84.67%\n",
      "69\tValidation loss: 0.4610\tBest loss: 0.4610\tAccuracy: 84.67%\n",
      "70\tValidation loss: 0.4597\tBest loss: 0.4597\tAccuracy: 84.67%\n",
      "71\tValidation loss: 0.4582\tBest loss: 0.4582\tAccuracy: 84.67%\n",
      "72\tValidation loss: 0.4566\tBest loss: 0.4566\tAccuracy: 84.67%\n",
      "73\tValidation loss: 0.4551\tBest loss: 0.4551\tAccuracy: 85.33%\n",
      "74\tValidation loss: 0.4537\tBest loss: 0.4537\tAccuracy: 85.33%\n",
      "75\tValidation loss: 0.4525\tBest loss: 0.4525\tAccuracy: 85.33%\n",
      "76\tValidation loss: 0.4515\tBest loss: 0.4515\tAccuracy: 85.33%\n",
      "77\tValidation loss: 0.4507\tBest loss: 0.4507\tAccuracy: 85.33%\n",
      "78\tValidation loss: 0.4501\tBest loss: 0.4501\tAccuracy: 85.33%\n",
      "79\tValidation loss: 0.4497\tBest loss: 0.4497\tAccuracy: 85.33%\n",
      "80\tValidation loss: 0.4494\tBest loss: 0.4494\tAccuracy: 85.33%\n",
      "81\tValidation loss: 0.4492\tBest loss: 0.4492\tAccuracy: 85.33%\n",
      "82\tValidation loss: 0.4489\tBest loss: 0.4489\tAccuracy: 85.33%\n",
      "83\tValidation loss: 0.4486\tBest loss: 0.4486\tAccuracy: 85.33%\n",
      "84\tValidation loss: 0.4482\tBest loss: 0.4482\tAccuracy: 85.33%\n",
      "85\tValidation loss: 0.4477\tBest loss: 0.4477\tAccuracy: 85.33%\n",
      "86\tValidation loss: 0.4471\tBest loss: 0.4471\tAccuracy: 85.33%\n",
      "87\tValidation loss: 0.4465\tBest loss: 0.4465\tAccuracy: 85.33%\n",
      "88\tValidation loss: 0.4459\tBest loss: 0.4459\tAccuracy: 85.33%\n",
      "89\tValidation loss: 0.4453\tBest loss: 0.4453\tAccuracy: 85.33%\n",
      "90\tValidation loss: 0.4448\tBest loss: 0.4448\tAccuracy: 85.33%\n",
      "91\tValidation loss: 0.4444\tBest loss: 0.4444\tAccuracy: 85.33%\n",
      "92\tValidation loss: 0.4440\tBest loss: 0.4440\tAccuracy: 86.00%\n",
      "93\tValidation loss: 0.4437\tBest loss: 0.4437\tAccuracy: 86.00%\n",
      "94\tValidation loss: 0.4435\tBest loss: 0.4435\tAccuracy: 86.00%\n",
      "95\tValidation loss: 0.4432\tBest loss: 0.4432\tAccuracy: 86.00%\n",
      "96\tValidation loss: 0.4429\tBest loss: 0.4429\tAccuracy: 86.00%\n",
      "97\tValidation loss: 0.4426\tBest loss: 0.4426\tAccuracy: 86.00%\n",
      "98\tValidation loss: 0.4423\tBest loss: 0.4423\tAccuracy: 86.67%\n",
      "99\tValidation loss: 0.4420\tBest loss: 0.4420\tAccuracy: 86.67%\n",
      "100\tValidation loss: 0.4416\tBest loss: 0.4416\tAccuracy: 86.67%\n",
      "101\tValidation loss: 0.4412\tBest loss: 0.4412\tAccuracy: 86.67%\n",
      "102\tValidation loss: 0.4409\tBest loss: 0.4409\tAccuracy: 86.67%\n",
      "103\tValidation loss: 0.4406\tBest loss: 0.4406\tAccuracy: 86.67%\n",
      "104\tValidation loss: 0.4403\tBest loss: 0.4403\tAccuracy: 86.67%\n",
      "105\tValidation loss: 0.4402\tBest loss: 0.4402\tAccuracy: 86.67%\n",
      "106\tValidation loss: 0.4400\tBest loss: 0.4400\tAccuracy: 86.67%\n",
      "107\tValidation loss: 0.4400\tBest loss: 0.4400\tAccuracy: 86.67%\n",
      "108\tValidation loss: 0.4399\tBest loss: 0.4399\tAccuracy: 86.67%\n",
      "109\tValidation loss: 0.4399\tBest loss: 0.4399\tAccuracy: 86.67%\n",
      "110\tValidation loss: 0.4399\tBest loss: 0.4399\tAccuracy: 86.67%\n",
      "111\tValidation loss: 0.4399\tBest loss: 0.4399\tAccuracy: 86.67%\n",
      "112\tValidation loss: 0.4399\tBest loss: 0.4399\tAccuracy: 86.67%\n",
      "113\tValidation loss: 0.4399\tBest loss: 0.4399\tAccuracy: 86.67%\n",
      "114\tValidation loss: 0.4398\tBest loss: 0.4398\tAccuracy: 86.67%\n",
      "115\tValidation loss: 0.4398\tBest loss: 0.4398\tAccuracy: 86.67%\n",
      "116\tValidation loss: 0.4397\tBest loss: 0.4397\tAccuracy: 86.67%\n",
      "117\tValidation loss: 0.4397\tBest loss: 0.4397\tAccuracy: 86.67%\n",
      "118\tValidation loss: 0.4396\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "119\tValidation loss: 0.4396\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "120\tValidation loss: 0.4396\tBest loss: 0.4396\tAccuracy: 87.33%\n",
      "121\tValidation loss: 0.4396\tBest loss: 0.4396\tAccuracy: 87.33%\n",
      "122\tValidation loss: 0.4397\tBest loss: 0.4396\tAccuracy: 87.33%\n",
      "123\tValidation loss: 0.4397\tBest loss: 0.4396\tAccuracy: 87.33%\n",
      "124\tValidation loss: 0.4397\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "125\tValidation loss: 0.4398\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "126\tValidation loss: 0.4398\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "127\tValidation loss: 0.4398\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "128\tValidation loss: 0.4399\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "129\tValidation loss: 0.4400\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "130\tValidation loss: 0.4400\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "131\tValidation loss: 0.4401\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "132\tValidation loss: 0.4402\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "133\tValidation loss: 0.4403\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "134\tValidation loss: 0.4405\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "135\tValidation loss: 0.4406\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "136\tValidation loss: 0.4407\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "137\tValidation loss: 0.4409\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "138\tValidation loss: 0.4410\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "139\tValidation loss: 0.4412\tBest loss: 0.4396\tAccuracy: 86.67%\n",
      "early stop\n",
      "INFO:tensorflow:Restoring parameters from Team58_HW3_3\\Team58_HW3_3.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 84.8385095596 %\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "early_stop_max_steps = 20\n",
    "steps_without_progress = 0\n",
    "best_loss = 9999999\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"Team58_HW2\\Team58_HW2.ckpt\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: X_train2, y: y_train2})\n",
    "        now_loss = sess.run(loss, feed_dict={X: X_valid2, y: y_valid2})\n",
    "        now_acc = sess.run(accuracy, feed_dict={X: X_valid2, y: y_valid2})\n",
    "        ## early stop implementation ##\n",
    "        if now_loss < best_loss:\n",
    "            HW3_3_saver.save(sess, \"Team58_HW3_3\\Team58_HW3_3.ckpt\")\n",
    "            best_loss = now_loss\n",
    "            steps_without_progress = 0\n",
    "        else:\n",
    "            steps_without_progress += 1\n",
    "            if steps_without_progress > early_stop_max_steps:\n",
    "                print(\"early stop\")\n",
    "                break\n",
    "        ## print result per epoch ##\n",
    "        print(\"{}\\tValidation loss: {:.4f}\\tBest loss: {:.4f}\\tAccuracy: {:.2f}%\".format(epoch, now_loss, best_loss, now_acc * 100))\n",
    "\n",
    "    HW3_3_saver.restore(sess, \"Team58_HW3_3\\Team58_HW3_3.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"test accuracy\",acc_test * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3-4 Bonus, accuracy: 88.95% , better than HW3(84.84%) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"layer1||layer2||layer4_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(0.01, name=\"Adamgram\")\n",
    "training_op = optimizer.minimize(loss, var_list=trainable_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "HW3_4_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from Team58_HW3_3\\Team58_HW3_3.ckpt\n",
      "0\tValidation loss: 2.7127\tBest loss: 2.7127\tAccuracy: 72.00%\n",
      "1\tValidation loss: 12.0427\tBest loss: 2.7127\tAccuracy: 50.00%\n",
      "2\tValidation loss: 5.4907\tBest loss: 2.7127\tAccuracy: 53.33%\n",
      "3\tValidation loss: 2.5905\tBest loss: 2.5905\tAccuracy: 51.33%\n",
      "4\tValidation loss: 2.6312\tBest loss: 2.5905\tAccuracy: 64.67%\n",
      "5\tValidation loss: 5.6698\tBest loss: 2.5905\tAccuracy: 56.00%\n",
      "6\tValidation loss: 2.2863\tBest loss: 2.2863\tAccuracy: 76.67%\n",
      "7\tValidation loss: 2.7342\tBest loss: 2.2863\tAccuracy: 67.33%\n",
      "8\tValidation loss: 2.6941\tBest loss: 2.2863\tAccuracy: 75.33%\n",
      "9\tValidation loss: 1.5286\tBest loss: 1.5286\tAccuracy: 74.00%\n",
      "10\tValidation loss: 1.0886\tBest loss: 1.0886\tAccuracy: 86.67%\n",
      "11\tValidation loss: 1.7085\tBest loss: 1.0886\tAccuracy: 80.00%\n",
      "12\tValidation loss: 0.9926\tBest loss: 0.9926\tAccuracy: 86.67%\n",
      "13\tValidation loss: 0.9248\tBest loss: 0.9248\tAccuracy: 88.00%\n",
      "14\tValidation loss: 1.3075\tBest loss: 0.9248\tAccuracy: 83.33%\n",
      "15\tValidation loss: 1.2049\tBest loss: 0.9248\tAccuracy: 86.00%\n",
      "16\tValidation loss: 1.0871\tBest loss: 0.9248\tAccuracy: 89.33%\n",
      "17\tValidation loss: 1.2439\tBest loss: 0.9248\tAccuracy: 90.00%\n",
      "18\tValidation loss: 1.4791\tBest loss: 0.9248\tAccuracy: 86.67%\n",
      "19\tValidation loss: 1.4532\tBest loss: 0.9248\tAccuracy: 88.00%\n",
      "20\tValidation loss: 1.3123\tBest loss: 0.9248\tAccuracy: 91.33%\n",
      "21\tValidation loss: 1.2377\tBest loss: 0.9248\tAccuracy: 91.33%\n",
      "22\tValidation loss: 1.2340\tBest loss: 0.9248\tAccuracy: 92.00%\n",
      "23\tValidation loss: 1.2800\tBest loss: 0.9248\tAccuracy: 92.00%\n",
      "24\tValidation loss: 1.2795\tBest loss: 0.9248\tAccuracy: 92.00%\n",
      "25\tValidation loss: 1.2594\tBest loss: 0.9248\tAccuracy: 91.33%\n",
      "26\tValidation loss: 1.2789\tBest loss: 0.9248\tAccuracy: 92.67%\n",
      "27\tValidation loss: 1.3280\tBest loss: 0.9248\tAccuracy: 91.33%\n",
      "28\tValidation loss: 1.3669\tBest loss: 0.9248\tAccuracy: 91.33%\n",
      "29\tValidation loss: 1.3933\tBest loss: 0.9248\tAccuracy: 91.33%\n",
      "30\tValidation loss: 1.4194\tBest loss: 0.9248\tAccuracy: 91.33%\n",
      "31\tValidation loss: 1.4474\tBest loss: 0.9248\tAccuracy: 92.00%\n",
      "32\tValidation loss: 1.4755\tBest loss: 0.9248\tAccuracy: 92.00%\n",
      "33\tValidation loss: 1.5020\tBest loss: 0.9248\tAccuracy: 92.00%\n",
      "early stop\n",
      "INFO:tensorflow:Restoring parameters from Team58_HW3_4\\Team58_HW3_4.ckpt\n",
      "test accuracy 88.9528930187 %\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "\n",
    "early_stop_max_steps = 20\n",
    "steps_without_progress = 0\n",
    "best_loss = 9999999\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    HW3_3_saver.restore(sess, \"Team58_HW3_3\\Team58_HW3_3.ckpt\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: X_train2, y: y_train2})\n",
    "        now_loss = sess.run(loss, feed_dict={X: X_valid2, y: y_valid2})\n",
    "        now_acc = sess.run(accuracy, feed_dict={X: X_valid2, y: y_valid2})\n",
    "        ## early stop implementation ##\n",
    "        if now_loss < best_loss:\n",
    "            HW3_4_saver.save(sess, \"Team58_HW3_4\\Team58_HW3_4.ckpt\")\n",
    "            best_loss = now_loss\n",
    "            steps_without_progress = 0\n",
    "        else:\n",
    "            steps_without_progress += 1\n",
    "            if steps_without_progress > early_stop_max_steps:\n",
    "                print(\"early stop\")\n",
    "                break\n",
    "        ## print result per epoch ##\n",
    "        print(\"{}\\tValidation loss: {:.4f}\\tBest loss: {:.4f}\\tAccuracy: {:.2f}%\".format(epoch, now_loss, best_loss, now_acc * 100))\n",
    "\n",
    "    HW3_4_saver.restore(sess, \"Team58_HW3_4\\Team58_HW3_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"test accuracy\",acc_test * 100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
